{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Collaboration (All 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_Report = {\n",
    "  \"GPT\": {\n",
    "    \"History\": \"continuity and change over time\",\n",
    "    \"US_Government\": \"Analyzing evidence\",\n",
    "    \"Physics\": \"Analyzing evidence\",\n",
    "    \"Human_Geography\": \"Contextualization\",\n",
    "    \"Environmental_Science\": \"Analyzing evidence\"\n",
    "  },\n",
    "  \"Gemini\": {\n",
    "    \"History\": \"Continuity and change over time\",\n",
    "    \"US_Government\": \"Analyzing evidence\",\n",
    "    \"Physics\": \"Causation\",\n",
    "    \"Human_Geography\": \"Causation\",\n",
    "    \"Environmental_Science\": \"Analyzing evidence\"\n",
    "  },\n",
    "  \"Claude\": {\n",
    "    \"History\": \"Analyzing evidence\",\n",
    "    \"US_Government\": \"Contextualization\",\n",
    "    \"Physics\": \"Analyzing evidence\",\n",
    "    \"Human_Geography\": \"Causation\",\n",
    "    \"Environmental_Science\": \"Analyzing evidence\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "genai.configure(api_key=\"\")\n",
    "model = genai.GenerativeModel('gemini-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "Claude_client = anthropic.Anthropic(api_key=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Test (question):\n",
    "#### History Test = question[1]- question[55]\n",
    "#### Government Test = question[1]- question[96]\n",
    "#### Physics Test = question[1]- question[75]\n",
    "#### Human Geo Test = question[1]- question[105]\n",
    "#### Env Sci Test = question[1]- question[157]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = \"physics\" # Please update to correct Subject\n",
    "def load_questions_from_folder(folder_path):\n",
    "    question = {}\n",
    "    for i in range(1, 76):  # add 1 more to the last question number to include it!\n",
    "        file_name = f\"Question{i}.txt\"\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                question[i] = file.read()\n",
    "        except UnicodeDecodeError:\n",
    "            with open(file_path, 'r', encoding='cp1252') as file:\n",
    "                question[i] = file.read()\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {file_path}\")\n",
    "            continue  \n",
    "\n",
    "    return question\n",
    "\n",
    "folder_path = \"\" # use /content/\n",
    "question = load_questions_from_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Answers_path = \"\" #update here\n",
    "try:\n",
    "    with open(Answers_path, 'r', encoding='utf-8') as file:\n",
    "        physics_answers = file.read() #update here\n",
    "except UnicodeDecodeError:\n",
    "    with open(Answers_path, 'r', encoding='cp1252') as file:  \n",
    "        physics_answers = file.read() #update here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Round 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Round_1_GPT_answer = {}\n",
    "\n",
    "for i in range(1, 76): # Add 1 more to the last question number to include it\n",
    "    output = client.chat.completions.create(\n",
    "            model='gpt-4',\n",
    "            messages=[{\"role\": \"user\", \"content\": f\"Please answer the questions with the question number and your letter of choice. Please remove parentheses from your letter of choice. Please provide a confidence level for your letter choice from 0% being the least likely correct answer choice to 100% being the most likely correct answer choice. Please also include a 1 sentence explanation for your choice justification. Please answer according to the example format: '1. A 90% because...' Now, please answer question {i}: \\n{question[i]}\\n\"}],\n",
    "        )\n",
    "    Round_1_GPT_answer[i] = output.choices[0].message.content\n",
    "    print(output.choices[0].message.content)\n",
    "\n",
    "print(\"All questions processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Round_1_GPT_answer[75]) #preview an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_safety_settings = {\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "}\n",
    "Round_1_Gemini_answer = {}\n",
    "\n",
    "i = 1  # Start from the first question\n",
    "\n",
    "while i <= 75:  # change based on the ACTUAL last question\n",
    "    try:\n",
    "        response = model.generate_content(\n",
    "            contents=f\"Please answer the questions with the question number and your letter of choice. Please remove parentheses from your letter of choice. Please provide a confidence level for your letter choice from 0% being the least likely correct choice to 100% being the most likely correct answer. Please also include a 1 sentence explanation for your choice justification. Please answer according to the example format: '1. A 90% because...' Now, please answer question {i}: \\n{question[i]}\\n\",\n",
    "            safety_settings= no_safety_settings\n",
    "        )\n",
    "        Round_1_Gemini_answer[i] = response.text\n",
    "        print(response.text)\n",
    "        i += 1  # Move to the next question only if successful\n",
    "    except Exception as e:  # Catching a general exception\n",
    "        error_message = str(e)\n",
    "        if \"429\" in error_message or \"rate limit\" in error_message.lower():\n",
    "            print(f\"Rate limit error on question {i}: {error_message} - Sleeping longer and retrying...\")\n",
    "            time.sleep(4)  # Sleep longer if rate limit error occurs\n",
    "        else:\n",
    "            print(f\"Error on question {i}: {error_message} - Retrying...\")\n",
    "    finally:\n",
    "        time.sleep(3)  # Respect the API's request limit\n",
    "\n",
    "print(\"All questions processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Round_1_Gemini_answer[75]) #preview an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Round_1_Claude_answer = {}\n",
    "\n",
    "for i in range(1, 76): # Add 1 more to the last question number to include it\n",
    "    message = Claude_client.messages.create(\n",
    "            max_tokens=1000,\n",
    "            model=\"claude-3-opus-20240229\",\n",
    "            messages=[{\"role\": \"user\", \"content\": f\"Please answer the questions with the question number and your letter of choice. Please remove parentheses from your letter of choice. Please provide a confidence level for your letter choice from 0% being the least likely correct answer choice to 100% being the most likely correct answer choice. Please also include a 1 sentence explanation for your choice justification. Please answer according to the example format: '1. A 90% because...' Now, please answer question {i}: \\n{question[i]}\\n\"}],\n",
    "        )\n",
    "    Round_1_Claude_answer[i] = message.content[0].text\n",
    "    print(message.content[0].text)\n",
    "\n",
    "print(\"All questions processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Round_1_Claude_answer[75]) #preview an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_llm_agreement(GPT_answers, Gemini_answers, Claude_answers):\n",
    "    results = []\n",
    "    agreement_pattern = re.compile(r'(\\d+)\\s*[.:]?\\s*(?:\\(([A-E])\\)|([A-E]))', re.IGNORECASE)\n",
    "\n",
    "    for question_number in range(1, 76):\n",
    "        gpt_answer_text = GPT_answers[question_number]\n",
    "        gemini_answer_text = Gemini_answers[question_number]\n",
    "        claude_answer_text = Claude_answers[question_number]\n",
    "\n",
    "        # Extracting the first letter choice mentioned in their responses\n",
    "        gpt_match = agreement_pattern.search(gpt_answer_text)\n",
    "        gemini_match = agreement_pattern.search(gemini_answer_text)\n",
    "        claude_match = agreement_pattern.search(claude_answer_text)\n",
    "\n",
    "        if gpt_match and gemini_match and claude_match:\n",
    "            gpt_choice = gpt_match.group().upper()\n",
    "            gemini_choice = gemini_match.group().upper()\n",
    "            claude_choice = claude_match.group().upper()\n",
    "            # Check if all three LLMs agree\n",
    "            correctness = 1 if gpt_choice == gemini_choice == claude_choice else 0\n",
    "        else:\n",
    "            correctness = 0\n",
    "\n",
    "        results.append((question_number, correctness))\n",
    "\n",
    "    return results\n",
    "\n",
    "def initialize_csv_file(filename):\n",
    "    \"\"\"Initialize the CSV file with headers.\"\"\"\n",
    "    with open(filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Question Number\", \"Agreement (0/1)\", \"GPT Choice\", \"Gemini Choice\", \"Claude Choice\"])\n",
    "\n",
    "def update_csv(filename, results, GPT_answers, Gemini_answers, Claude_answers):\n",
    "    \"\"\"Update the CSV file with LLM agreement results.\"\"\"\n",
    "    with open(filename, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        agreement_pattern = re.compile(r'(\\d+)\\s*[.:]?\\s*(?:\\(([A-E])\\)|([A-E]))', re.IGNORECASE)\n",
    "\n",
    "        for question_number, correctness in results:\n",
    "            gpt_match = agreement_pattern.search(GPT_answers[question_number])\n",
    "            gemini_match = agreement_pattern.search(Gemini_answers[question_number])\n",
    "            claude_match = agreement_pattern.search(Claude_answers[question_number])\n",
    "            gpt_choice = gpt_match.group().upper() if gpt_match else \"N/A\"\n",
    "            gemini_choice = gemini_match.group().upper() if gemini_match else \"N/A\"\n",
    "            claude_choice = claude_match.group().upper() if claude_match else \"N/A\"\n",
    "\n",
    "            writer.writerow([question_number, correctness, gpt_choice, gemini_choice, claude_choice])\n",
    "                             \n",
    "filename = f\"All3_round_1_{subject}_Agree.csv\"\n",
    "initialize_csv_file(filename)\n",
    "results = evaluate_llm_agreement(Round_1_GPT_answer, Round_1_Gemini_answer, Round_1_Claude_answer)\n",
    "update_csv(filename, results, Round_1_GPT_answer, Round_1_Gemini_answer, Round_1_Claude_answer)\n",
    "print(f'Agreement CSV: {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_answer_key(answers):\n",
    "    answer_key = {}\n",
    "    for line in answers.splitlines():\n",
    "        parts = line.split()\n",
    "        if len(parts) >= 3:\n",
    "            question_number, correct_answer, skill = parts[0], parts[1], ' '.join(parts[2:])\n",
    "            answer_key[question_number] = (correct_answer, skill)\n",
    "    return answer_key\n",
    "\n",
    "def extract_choice(choice_text):\n",
    "    choice_text = str(choice_text)\n",
    "    match = re.search(r'\\b([A-E])\\b', choice_text, re.IGNORECASE)\n",
    "    return match.group(1).upper() if match else \"\"\n",
    "\n",
    "def grade_llm_answers(csv_filename, answer_key):\n",
    "    df = pd.read_csv(csv_filename)\n",
    "\n",
    "    # Initialize columns if they don't exist to avoid KeyErrors\n",
    "    for col in ['GPT Choice', 'Gemini Choice', 'Claude Choice']:\n",
    "        if col not in df.columns:\n",
    "            df[col] = \"\"\n",
    "\n",
    "    df['Truth'] = df['Question Number'].apply(lambda x: answer_key.get(str(x), ('', ''))[0])\n",
    "    df['Skill Assessed'] = df['Question Number'].apply(lambda x: answer_key.get(str(x), ('', ''))[1])\n",
    "    df['Correctness'] = 0\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        gpt_choice = extract_choice(row['GPT Choice'])\n",
    "        gemini_choice = extract_choice(row['Gemini Choice'])\n",
    "        claude_choice = extract_choice(row['Claude Choice'])\n",
    "\n",
    "        if gpt_choice == gemini_choice == claude_choice and gpt_choice == row['Truth']:\n",
    "            df.at[index, 'Correctness'] = 1\n",
    "\n",
    "    graded_filename = csv_filename.replace('Agree.csv', '_graded.csv')\n",
    "    df.to_csv(graded_filename, index=False)\n",
    "    print(f\"Graded results saved to {graded_filename}.\")\n",
    "\n",
    "answers = physics_answers # Update here\n",
    "answer_key = parse_answer_key(answers)\n",
    "csv_filename = filename\n",
    "grade_llm_answers(csv_filename, answer_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Round 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Round_2_GPT_answer = {}\n",
    "\n",
    "for i in range(1, 76): # Add 1 more to the last question number to include it\n",
    "    output = client.chat.completions.create(\n",
    "            model='gpt-4',\n",
    "            messages=[{\"role\": \"user\", \"content\": f\"Please answer the questions with the question number and your letter of choice. Please remove parentheses from your letter of choice. Please provide a confidence level for your letter choice from 0% being the least likely correct answer choice to 100% being the most likely correct answer choice. Please also include a 1 sentence explanation for your choice justification. Please answer according to the example format: '1. A 90% because...' Now, please answer question {i}: \\n{question[i]}\\n based on Gemini's reponse:'{Round_1_Gemini_answer[i]}' \\nClaude's response: '{Round_1_Claude_answer[i]}' \\nand your own previous response:'{Round_1_GPT_answer[i]}'. \\nLimit your choice to one of the previous responses\"}],\n",
    "        )\n",
    "    Round_2_GPT_answer[i] = output.choices[0].message.content\n",
    "    print(output.choices[0].message.content)\n",
    "\n",
    "print(\"All questions processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Round_2_GPT_answer[75]) #preview an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_safety_settings = {\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "}\n",
    "Round_2_Gemini_answer = {}\n",
    "\n",
    "i = 1  # Start from the first question\n",
    "\n",
    "while i <= 75:  # change based on last question\n",
    "    try:\n",
    "        response = model.generate_content(\n",
    "            contents=f\"Please answer the questions with the question number and your letter of choice. Please remove parentheses from your letter of choice. Please provide a confidence level for your letter choice from 0% being the least likely correct answer choice to 100% being the most likely correct answer choice. Please also include a 1 sentence explanation for your choice justification. Please answer according to the example format: '1. A 90% because...' Now, please answer question {i}: \\n{question[i]}\\n based on your previous reponse:'{Round_1_Gemini_answer[i]}',\\nClaude's response:{Round_1_Claude_answer[i]} \\nand GPT's response:'{Round_1_GPT_answer[i]}'. \\nLimit your choice to one of the previous responses\",\n",
    "            safety_settings= no_safety_settings\n",
    "        )\n",
    "        Round_2_Gemini_answer[i] = response.text\n",
    "        print(response.text)\n",
    "        i += 1 \n",
    "    except Exception as e:  # Catching a general exception\n",
    "        error_message = str(e)\n",
    "        if \"429\" in error_message or \"rate limit\" in error_message.lower():\n",
    "            print(f\"Rate limit error on question {i}: {error_message} - Sleeping longer and retrying...\")\n",
    "            time.sleep(4)  # Sleep longer if rate limit error occurs\n",
    "        else:\n",
    "            print(f\"Error on question {i}: {error_message} - Retrying...\")\n",
    "    finally:\n",
    "        time.sleep(3)  # Respect the API's request limit\n",
    "\n",
    "print(\"All questions processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Round_2_Gemini_answer[75]) #preview an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Round_2_Claude_answer = {}\n",
    "\n",
    "for i in range(1, 76): # Add 1 more to the last question number to include it\n",
    "    message = Claude_client.messages.create(\n",
    "            max_tokens=1000,\n",
    "            model=\"claude-3-opus-20240229\",\n",
    "            messages=[{\"role\": \"user\", \"content\": f\"Please answer the questions with the question number and your letter of choice. Please remove parentheses from your letter of choice. Please provide a confidence level for your letter choice from 0% being the least likely correct answer choice to 100% being the most likely correct answer choice. Please also include a 1 sentence explanation for your choice justification. Please answer according to the example format: '1. A 90% because...' Now, please answer question {i}: \\n{question[i]}\\n based on your previous reponse:'{Round_1_Claude_answer[i]}', \\nGPT's response:{Round_1_GPT_answer[i]}, \\nand Gemini's response:'{Round_1_Gemini_answer[i]}'. \\nLimit your choice to one of the previous responses\"}],\n",
    "        )\n",
    "    Round_2_Claude_answer[i] = message.content[0].text \n",
    "    print(message.content[0].text)\n",
    "\n",
    "print(\"All questions processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Round_2_Claude_answer[75]) #preview an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_llm_agreement(GPT_answers, Gemini_answers, Claude_answers):\n",
    "    results = []\n",
    "    agreement_pattern = re.compile(r'(\\d+)\\s*[.:]?\\s*(?:\\(([A-E])\\)|([A-E]))', re.IGNORECASE)\n",
    "\n",
    "    for question_number in range(1, 76): # Add 1 more to the last question number to include it\n",
    "        gpt_answer_text = GPT_answers[question_number]\n",
    "        gemini_answer_text = Gemini_answers[question_number]\n",
    "        claude_answer_text = Claude_answers[question_number]\n",
    "\n",
    "        # Extracting the first letter choice mentioned in their responses\n",
    "        gpt_match = agreement_pattern.search(gpt_answer_text)\n",
    "        gemini_match = agreement_pattern.search(gemini_answer_text)\n",
    "        claude_match = agreement_pattern.search(claude_answer_text)\n",
    "\n",
    "        if gpt_match and gemini_match and claude_match:\n",
    "            gpt_choice = gpt_match.group().upper()\n",
    "            gemini_choice = gemini_match.group().upper()\n",
    "            claude_choice = claude_match.group().upper()\n",
    "            # Check if all three LLMs agree\n",
    "            correctness = 1 if gpt_choice == gemini_choice == claude_choice else 0\n",
    "        else:\n",
    "            correctness = 0\n",
    "\n",
    "        results.append((question_number, correctness))\n",
    "\n",
    "    return results\n",
    "\n",
    "def initialize_csv_file(filename):\n",
    "    \"\"\"Initialize the CSV file with headers.\"\"\"\n",
    "    with open(filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Question Number\", \"Agreement (0/1)\", \"GPT Choice\", \"Gemini Choice\", \"Claude Choice\"])\n",
    "\n",
    "def update_csv(filename, results, GPT_answers, Gemini_answers, Claude_answers):\n",
    "    \"\"\"Update the CSV file with LLM agreement results.\"\"\"\n",
    "    with open(filename, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        agreement_pattern = re.compile(r'(\\d+)\\s*[.:]?\\s*(?:\\(([A-E])\\)|([A-E]))', re.IGNORECASE)\n",
    "\n",
    "        for question_number, correctness in results:\n",
    "            gpt_match = agreement_pattern.search(GPT_answers[question_number])\n",
    "            gemini_match = agreement_pattern.search(Gemini_answers[question_number])\n",
    "            claude_match = agreement_pattern.search(Claude_answers[question_number])\n",
    "            gpt_choice = gpt_match.group().upper() if gpt_match else \"N/A\"\n",
    "            gemini_choice = gemini_match.group().upper() if gemini_match else \"N/A\"\n",
    "            claude_choice = claude_match.group().upper() if claude_match else \"N/A\"\n",
    "\n",
    "            writer.writerow([question_number, correctness, gpt_choice, gemini_choice, claude_choice])\n",
    "                             \n",
    "filename = f\"All3_round_2_{subject}_Agree.csv\"\n",
    "initialize_csv_file(filename)\n",
    "results = evaluate_llm_agreement(Round_2_GPT_answer, Round_2_Gemini_answer, Round_2_Claude_answer)\n",
    "update_csv(filename, results, Round_2_GPT_answer, Round_2_Gemini_answer, Round_2_Claude_answer)\n",
    "print(f'Agreement CSV: {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_answer_key(answers):\n",
    "    answer_key = {}\n",
    "    for line in answers.splitlines():\n",
    "        parts = line.split()\n",
    "        if len(parts) >= 3:\n",
    "            question_number, correct_answer, skill = parts[0], parts[1], ' '.join(parts[2:])\n",
    "            answer_key[question_number] = (correct_answer, skill)\n",
    "    return answer_key\n",
    "\n",
    "def extract_choice(choice_text):\n",
    "    choice_text = str(choice_text)\n",
    "    match = re.search(r'\\b([A-E])\\b', choice_text, re.IGNORECASE)\n",
    "    return match.group(1).upper() if match else \"\"\n",
    "\n",
    "def grade_llm_answers(csv_filename, answer_key):\n",
    "    df = pd.read_csv(csv_filename)\n",
    "\n",
    "    # Initialize columns if they don't exist to avoid KeyErrors\n",
    "    for col in ['GPT Choice', 'Gemini Choice', 'Claude Choice']:\n",
    "        if col not in df.columns:\n",
    "            df[col] = \"\"\n",
    "\n",
    "    df['Truth'] = df['Question Number'].apply(lambda x: answer_key.get(str(x), ('', ''))[0])\n",
    "    df['Skill Assessed'] = df['Question Number'].apply(lambda x: answer_key.get(str(x), ('', ''))[1])\n",
    "    df['Correctness'] = 0\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        gpt_choice = extract_choice(row['GPT Choice'])\n",
    "        gemini_choice = extract_choice(row['Gemini Choice'])\n",
    "        claude_choice = extract_choice(row['Claude Choice'])\n",
    "\n",
    "        if gpt_choice == gemini_choice == claude_choice and gpt_choice == row['Truth']:\n",
    "            df.at[index, 'Correctness'] = 1\n",
    "\n",
    "    graded_filename = csv_filename.replace('Agree.csv', '_graded.csv')\n",
    "    df.to_csv(graded_filename, index=False)\n",
    "    print(f\"Graded results saved to {graded_filename}.\")\n",
    "\n",
    "\n",
    "answers = physics_answers # Update here\n",
    "answer_key = parse_answer_key(answers)\n",
    "csv_filename = filename\n",
    "grade_llm_answers(csv_filename, answer_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Round 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_skills_assessed(answers):\n",
    "    skills_assessed = {}\n",
    "    for line in answers.splitlines():\n",
    "        parts = line.split()\n",
    "        if len(parts) >= 3:\n",
    "            question_number = parts[0]\n",
    "            skill = ' '.join(parts[2:])\n",
    "            skills_assessed[question_number] = skill\n",
    "    return skills_assessed\n",
    "\n",
    "skills_assessed = parse_skills_assessed(answers)\n",
    "\n",
    "\n",
    "def parse_answer_key(answers):\n",
    "    answer_key = {}\n",
    "    for line in answers.splitlines():\n",
    "        parts = line.split()\n",
    "        if len(parts) >= 3:\n",
    "            question_number, correct_answer, skill = parts[0], parts[1], ' '.join(parts[2:])\n",
    "            answer_key[question_number] = (correct_answer, skill)\n",
    "    return answer_key\n",
    "\n",
    "def extract_letter_choice(text):\n",
    "    match = re.search(r'\\b([A-E])\\b', text, re.IGNORECASE)\n",
    "    return match.group(1).upper() if match else None\n",
    "\n",
    "def initialize_csv_file(filename, subject):\n",
    "    with open(filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([f\"{subject}_Question Number\", f\"{subject}_Correctness\", f\"{subject}_Choice\", f\"{subject}_Skill Assessed\"])\n",
    "\n",
    "def update_csv(filename, answers, subject, answer_key):\n",
    "    with open(filename, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for i in range(1, 76):  # Add 1 more to the last question number to include it\n",
    "            answer_text = answers[i] if i in answers else \"\"\n",
    "            choice = extract_letter_choice(answer_text)\n",
    "            correct = 1 if answer_key.get(str(i), ('', ''))[0] == choice else 0\n",
    "            skill_assessed = answer_key.get(str(i), ('', ''))[1]\n",
    "            writer.writerow([f\"{subject}_{i}\", correct, choice, skill_assessed])\n",
    "\n",
    "def ask_claude_all_questions(subject, filename, answer_key):\n",
    "    initialize_csv_file(filename, subject)  \n",
    "    claude_answers = {}  \n",
    "\n",
    "    for i in range(1, 76):  # Add 1 more to the last question number to include it\n",
    "        message = Claude_client.messages.create(\n",
    "            max_tokens=1000,\n",
    "            messages=[{\"role\": \"user\", \"content\": f\"Please answer the questions with only the question number and your letter of choice. Please remove parentheses from your letter of choice. Please answer according to the example format: '1. A' Now, please answer question {i}: \\n{question[i]}\\n based on Gemini's reponse:'{Round_2_Gemini_answer[i]}', \\nand GPT's response:'{Round_2_GPT_answer[i]}', and your previous response: '{Round_2_Claude_answer[i]}'. The percentage provided for their responses is their confidence level from 0% being least likely to be correct and 100% being most likely to be the correct answer. This question assess the skill of: {skills_assessed[str(i)]} \\nYou are the judge and you can decide to choose which LLM's choice you want to choose. You can also decide to choose none of the previous LLM's choices. Also decide based on each LLM's weaknesses:{LLM_Report}\"}],\n",
    "            model=\"claude-3-opus-20240229\"\n",
    "        )\n",
    "        claude_answers[i] = message.content[0].text \n",
    "        print(f\"Question {i}: {claude_answers[i]}\")\n",
    "\n",
    "    update_csv(filename, claude_answers, subject, answer_key) \n",
    "    print(f\"Round 3 finalized. Results added to {filename}.\")\n",
    "\n",
    "filename = f\"All3_Round_3_{subject}_Results.csv\"\n",
    "answers = physics_answers  \n",
    "answer_key = parse_answer_key(answers)\n",
    "ask_claude_all_questions(subject, filename, answer_key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
